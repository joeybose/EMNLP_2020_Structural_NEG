\section{Structure Aware Negative Sampling}
\label{sec:proposedapproach}
In this paper, we seek to explicitly use the rich graph structure surrounding a particular node when generating negative triplets. We motivate our approach based on the observation that prior work in learning word embeddings \cite{mikolov2013distributed}, where negative sampling has historically developed, lacked the richness of graph structure that is immediately accessible in the KG setting. Consequently, we hypothesize that enriching the negative sampling process with structural information in KG can yield harder negative examples, crucial to learning of effective embeddings. Figure \ref{fig:arch} highlights our approach and in the first step requires the construction of a $k$-hop neighbourhood ($K$) for each node, which can be computed as follows: 
\begin{equation}
\label{eqn:khop}
\mathbb{K} = A^{k} + A^{k-1}
\end{equation}
for $k>0$, where $k$ is an integer, representing the desired neighbourhood radius and $A$ is the adjacency matrix for the KG.

To construct negatives triplets, we may now simply sample from the $\mathbb{K}$, which represents a subset of all entities in the KG ---i.e. $\mathbb{K} \subset E$. Thus, selected negative triples satisfy the following criterion:
\begin{equation*}
    (h',r,t') = \{ (h',r,t)|h'\in \mathbb{K}\} \cup \{(h,r,t')|t'\in \mathbb{K} \}  \\
\end{equation*}
\cut{
with $ \mathbb{K} \subset E$, where $K$ is the \emph{k-hop} neighbourhood of $h$ or $t$, and $E$ is the entire sample space.} Intuitively, SANS exploits the locality of an entity's neighborhood, where negative samples are defined to be head or tail entities that are not directly linked under a relation $r$ but can be accessed through a path of at most length $k$.We argue that such local negatives are harder to distinguish and lead to higher scores as evaluated by the embedding model. One important technical detail in constructing $\mathbb{K}$ is the existence of multiple relation types, which requires an additional dimension to represent the graph connectivity and local neighborhoods as adjacency and \emph{k-hop} tensors.

\subsection{Variants of SANS}
Although, SANS requires a one time preprocessing step in order to construct $\mathbb{K}$ as defined in Eqn \ref{eqn:khop}, this may still be costly for large and dense KGs. To combat this inefficiency we introduce Random Walk SANS, which uses random walks of length $k$ on the adjacency tensor \cite{perozzi2014deepwalk} to approximate the \emph{k-hop} neighbourhood within the KG. Thus the number of random walks trades of the computational cost with approximation accuracy of the true $\mathbb{K}$.

As SANS constructs a local neighborhood from which negative samples are drawn, it can also be combined with other negative sampling approaches. In this work, we extend the Self-Adversarial approach in \cite{sun2019rotate} and combine it with SANS by restricting the negative triplet candidate set to the \emph{k-hop} neighbourhood. In the subsequent sections, we refer to this technique as \emph{Self-Adversarial SANS}, whereas the former approach is referred to as \emph{Uniform SANS}. 

\cut{
Computing Eq. \ref{eqn:khop} can be costly for large KGs, the \emph{k-hop} neighbourhood can be approximated using \emph{Random Walks (RW)} \cite{perozzi2014deepwalk} by Algorithm \ref{alg:rw}, where $\omega$ is the number of RWs, and $k$ is the number of k-hops.

\begin{algorithm}[tb]
   \caption{\small Approximating K-hop neighbourhood using RWs}
   \label{alg:rw}
  \begin{small}
\begin{algorithmic}
   \STATE {\bfseries Input:} $A, k, \omega$
   \COMMENT A: Adjacency Matrix, k: \# of k-hops, $\omega$: \# of RWs
   \STATE {$K \gets$ sparseMatrix($|A| \times |A|$)}
   \FORALL {entity $e$}
   \STATE {$K[e] \gets $} randomWalk(k, $\omega$)
   \ENDFOR
   \STATE {\textbf{return}} $K$
\end{algorithmic}
\end{small}
\end{algorithm}}

